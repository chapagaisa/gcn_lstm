{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2a6db7c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b2a6db7c",
    "outputId": "15c10667-a9a8-447d-87ae-4fbf42fffe70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch v:  1.13.1+cu116\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print('Torch v: ', torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "681de281",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "681de281",
    "outputId": "8af70024-1087-4b31-a847-8c070189de95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting sktime\n",
      "  Downloading sktime-0.16.1-py3-none-any.whl (16.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn<1.3.0,>=0.24.0 in /usr/local/lib/python3.9/dist-packages (from sktime) (1.2.2)\n",
      "Collecting deprecated>=1.2.13\n",
      "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from sktime) (1.10.1)\n",
      "Requirement already satisfied: numba>=0.53 in /usr/local/lib/python3.9/dist-packages (from sktime) (0.56.4)\n",
      "Requirement already satisfied: pandas<1.6.0,>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from sktime) (1.4.4)\n",
      "Requirement already satisfied: numpy<1.25,>=1.21.0 in /usr/local/lib/python3.9/dist-packages (from sktime) (1.22.4)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.9/dist-packages (from deprecated>=1.2.13->sktime) (1.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from numba>=0.53->sktime) (63.4.3)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.9/dist-packages (from numba>=0.53->sktime) (0.39.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas<1.6.0,>=1.1.0->sktime) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas<1.6.0,>=1.1.0->sktime) (2022.7.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn<1.3.0,>=0.24.0->sktime) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn<1.3.0,>=0.24.0->sktime) (1.1.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas<1.6.0,>=1.1.0->sktime) (1.15.0)\n",
      "Installing collected packages: deprecated, sktime\n",
      "Successfully installed deprecated-1.2.13 sktime-0.16.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "!pip install sktime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fc5eeff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "6fc5eeff",
    "outputId": "edb63bef-7547-46fc-daed-7db72d0e5936"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Looking in links: https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
      "Collecting torch-scatter\n",
      "  Downloading torch_scatter-2.1.1.tar.gz (107 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.6/107.6 KB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Building wheels for collected packages: torch-scatter\n",
      "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for torch-scatter: filename=torch_scatter-2.1.1-cp39-cp39-linux_x86_64.whl size=3507048 sha256=b6c9e2de50859a148963b8ff2b326a8a12335ef4dffa4cd15f94e0278ed290e6\n",
      "  Stored in directory: /root/.cache/pip/wheels/d5/0c/18/11b4cf31446c5d460543b0fff930fcac3a3f8a785e5c73fb15\n",
      "Successfully built torch-scatter\n",
      "Installing collected packages: torch-scatter\n",
      "Successfully installed torch-scatter-2.1.1\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Looking in links: https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
      "Collecting torch-sparse\n",
      "  Downloading torch_sparse-0.6.16.tar.gz (208 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.2/208.2 KB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from torch-sparse) (1.10.1)\n",
      "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.9/dist-packages (from scipy->torch-sparse) (1.22.4)\n",
      "Building wheels for collected packages: torch-sparse\n",
      "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for torch-sparse: filename=torch_sparse-0.6.16-cp39-cp39-linux_x86_64.whl size=2748563 sha256=6dea2bfec7ade48bcf9cdb38cf6ea7fc9f7d2f5a3c066d93c3f834be0b14e72c\n",
      "  Stored in directory: /root/.cache/pip/wheels/7f/f3/e7/dfe620cda3bd0fabb2b5537548e53314539b4dd2d0a9eee06f\n",
      "Successfully built torch-sparse\n",
      "Installing collected packages: torch-sparse\n",
      "Successfully installed torch-sparse-0.6.16\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting torch-geometric\n",
      "  Downloading torch_geometric-2.2.0.tar.gz (564 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m565.0/565.0 KB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (4.65.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (1.22.4)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (1.10.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (3.1.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (2.25.1)\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (3.0.9)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (1.2.2)\n",
      "Collecting psutil>=5.8.0\n",
      "  Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.2/280.2 KB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch-geometric) (2.1.2)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->torch-geometric) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torch-geometric) (1.26.15)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torch-geometric) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torch-geometric) (2022.12.7)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->torch-geometric) (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
      "Building wheels for collected packages: torch-geometric\n",
      "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for torch-geometric: filename=torch_geometric-2.2.0-py3-none-any.whl size=773302 sha256=e554add8a26601bd02e02fa1c129f72c51e50a3847d07c48f170ecf49b3c7e51\n",
      "  Stored in directory: /root/.cache/pip/wheels/31/b2/8c/9b4bb72a4384eabd1ffeab2b7ead692c9165e35711f8a9dc72\n",
      "Successfully built torch-geometric\n",
      "Installing collected packages: psutil, torch-geometric\n",
      "  Attempting uninstall: psutil\n",
      "    Found existing installation: psutil 5.4.8\n",
      "    Uninstalling psutil-5.4.8:\n",
      "      Successfully uninstalled psutil-5.4.8\n",
      "Successfully installed psutil-5.9.4 torch-geometric-2.2.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "psutil"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install torch-scatter -f https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
    "!pip install torch-sparse -f https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
    "!pip install torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b86ad31e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b86ad31e",
    "outputId": "9421b340-3c05-4bb5-9764-ae723394eb67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(268, 6)\n",
      "(293, 6)\n",
      "<class 'pandas.core.series.Series'>\n",
      "(896,)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1]\n",
      "Train shape:  (268, 6, 896)   type:  <class 'numpy.ndarray'>\n",
      "Test shape:  (293, 6, 896)   type:  <class 'numpy.ndarray'>\n",
      "Train Label shape:  (268,)   type:  <class 'numpy.ndarray'>\n",
      "Test Label shape:  (293,)   type:  <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "from sktime.datasets import load_from_arff_to_dataframe\n",
    "from sktime.datasets import load_from_tsfile\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X_train, y_train = load_from_arff_to_dataframe(\"SelfRegulationSCP1_TRAIN.arff\")\n",
    "X_test, y_test = load_from_arff_to_dataframe(\"SelfRegulationSCP1_TEST.arff\")\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(type(X_train.iloc[1, 1]))\n",
    "\n",
    "print((X_train.iloc[1, 1].shape))\n",
    "X_train.head()\n",
    "\n",
    "\n",
    "#Convert pandas series into numpy array\n",
    "X_train = np.array(X_train.values.tolist())\n",
    "X_test = np.array(X_test.values.tolist())\n",
    "\n",
    "#Convert alphabet label into numeric\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.fit_transform(y_test)\n",
    "print(y_train)\n",
    "\n",
    "print(\"Train shape: \", X_train.shape, \"  type: \", type(X_train))\n",
    "print(\"Test shape: \", X_test.shape, \"  type: \", type(X_test))\n",
    "print(\"Train Label shape: \", y_train.shape, \"  type: \", type(y_train))\n",
    "print(\"Test Label shape: \", y_test.shape, \"  type: \", type(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b685b4c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4b685b4c",
    "outputId": "3957079c-ded7-431c-e2d0-fac625520587"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The class labels\n",
    "np.unique(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3ff40a4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d3ff40a4",
    "outputId": "621e2e7b-a4c4-46e4-f03e-f2d2f15d9b1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (268, 6, 896)\n",
      "y_train shape:  (268,)\n",
      "X_test shape:  (293, 6, 896)\n",
      "y_test shape:  (293,)\n",
      "y_train_counts\n",
      "{0: 135, 1: 133}\n",
      "y_test_counts\n",
      "{0: 147, 1: 146}\n"
     ]
    }
   ],
   "source": [
    "#check\n",
    "print(\"X_train shape: \", X_train.shape)\n",
    "print(\"y_train shape: \", y_train.shape)\n",
    "print(\"X_test shape: \", X_test.shape)\n",
    "print(\"y_test shape: \", y_test.shape)\n",
    "unique_y_train, counts_y_train = np.unique(y_train, return_counts=True)\n",
    "y_train_stats = dict(zip(unique_y_train, counts_y_train))\n",
    "print(\"y_train_counts\")\n",
    "print(y_train_stats)\n",
    "#270/(269+269+270+270) = 0.25\n",
    "unique_y_test, counts_y_test = np.unique(y_test, return_counts=True)\n",
    "y_test_stats = dict(zip(unique_y_test, counts_y_test))\n",
    "print(\"y_test_counts\")\n",
    "print(y_test_stats)\n",
    "#116/(116+116+115+115) = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6fab737",
   "metadata": {
    "id": "c6fab737"
   },
   "outputs": [],
   "source": [
    "#graph utils\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "def get_adj_mat(c, th):\n",
    "  #print(\"Creating graph with th: \", th)\n",
    "  n = c.shape[0]\n",
    "  a = np.zeros((n,n))\n",
    "  for i in range(n):\n",
    "    for j in range(n):\n",
    "      #print(\"before:\", c[i,j])\n",
    "      if(c[i,j]>th):\n",
    "        a[i,j]=1\n",
    "        a[j,i]=1\n",
    "      #print(\"after:\", a[i,j])\n",
    "  return a\n",
    "\n",
    "def check_symmetric(a, rtol=1e-05, atol=1e-08):\n",
    "    return np.allclose(a, a.T, rtol=rtol, atol=atol)\n",
    "\n",
    "def build_edge_index_tensor(adj):\n",
    "  num_nodes = adj.shape[0]\n",
    "  source_nodes_ids, target_nodes_ids = [], []\n",
    "  for i in range(num_nodes):\n",
    "    for j in range(num_nodes):\n",
    "      if(adj[i,j]==1):\n",
    "        source_nodes_ids.append(i)\n",
    "        target_nodes_ids.append(j)\n",
    "  edge_index = np.row_stack((source_nodes_ids, target_nodes_ids))\n",
    "  edge_index_tensor = torch.from_numpy(edge_index)\n",
    "  return edge_index_tensor\n",
    "\n",
    "def normalize_node_attributes(mvts):\n",
    "  sc = StandardScaler()\n",
    "  mvts_std = sc.fit_transform(mvts)\n",
    "  return mvts_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6452110",
   "metadata": {
    "id": "e6452110"
   },
   "outputs": [],
   "source": [
    "#data crawler in train dataset\n",
    "th = 0\n",
    "num_train = X_train.shape[0]\n",
    "num_nodes = 6\n",
    "num_ts = 896\n",
    "train_adjs = np.zeros((num_train, num_nodes, num_nodes))\n",
    "train_nats = np.zeros((num_train, num_nodes, num_ts))\n",
    "for i in range(num_train):\n",
    "  #print('Event: ', i)\n",
    "  mt = X_train[i].T[:,:] #consider first 25 solar params\n",
    "  mt = normalize_node_attributes(mt) #[60,25]\n",
    "  c_mt = np.corrcoef(mt.T)#[25,25]\n",
    "  c_mt[np.isnan(c_mt)]=0\n",
    "  train_nats[i,:,:] = mt.T\n",
    "  adj = get_adj_mat(c_mt, th)\n",
    "  train_adjs[i,:,:]=adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b85a3cc6",
   "metadata": {
    "id": "b85a3cc6"
   },
   "outputs": [],
   "source": [
    "#data crawler in test dataset\n",
    "num_test = X_test.shape[0]\n",
    "#data crawler in train dataset\n",
    "test_adjs = np.zeros((num_test, num_nodes, num_nodes))\n",
    "test_nats = np.zeros((num_test, num_nodes, num_ts))\n",
    "for i in range(num_test):\n",
    "  #print('Event: ', i)\n",
    "  mt = X_test[i].T[:,:] #consider first 25 solar params\n",
    "  mt = normalize_node_attributes(mt) #[60,25]\n",
    "  c_mt = np.corrcoef(mt.T)#[25,25]\n",
    "  c_mt[np.isnan(c_mt)]=0\n",
    "  test_nats[i,:,:] = mt.T #[25,60]\n",
    "  adj = get_adj_mat(c_mt, th)\n",
    "  test_adjs[i,:,:]=adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9766f53c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9766f53c",
    "outputId": "b820f92f-287a-4c02-c480-737f4a324681"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(268, 6, 6)\n",
      "(268, 6, 896)\n",
      "(293, 6, 6)\n",
      "(293, 6, 896)\n"
     ]
    }
   ],
   "source": [
    "print(train_adjs.shape)\n",
    "print(train_nats.shape)\n",
    "print(test_adjs.shape)\n",
    "print(test_nats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b60e7ead",
   "metadata": {
    "id": "b60e7ead"
   },
   "outputs": [],
   "source": [
    "#MODELS CELL\n",
    "#node_emb_dim = graph_emb_dim = window_emb_dim = 4; sequence_emb_dim = 128; class_emb_dim = 4\n",
    "# (GCN) Node emb -> (mean) Graph emb -> (Flatten, Linear) -> window emb -> (LSTM) -> Temporal sequence emb -> (Linear) Class emb\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "class MVTS_GCN_RNN(torch.nn.Module):\n",
    "  def __init__(self, num_nodes, input_dims, device, sequence_emb_dims, gcn_hidden_dims, node_emb_dims, graph_emb_dims, event_emb_dims, num_classes):\n",
    "    super(MVTS_GCN_RNN, self).__init__()\n",
    "    self.num_nodes = num_nodes\n",
    "    self.input_dims = input_dims\n",
    "    self.device = device\n",
    "    self.sequence_emb_dims = sequence_emb_dims\n",
    "    self.gcn_hidden_dims = gcn_hidden_dims\n",
    "    self.node_emb_dims = node_emb_dims\n",
    "    self.graph_emb_dims = graph_emb_dims\n",
    "    self.num_classes = num_classes \n",
    "\n",
    "    self.mt2vector = nn.LSTM(num_nodes, sequence_emb_dims)\n",
    "    self.conv1 = GCNConv(input_dims, gcn_hidden_dims)\n",
    "    self.conv2 = GCNConv(gcn_hidden_dims, node_emb_dims)\n",
    "    #self.conv = GCNConv(input_dims, node_emb_dims)\n",
    "    #self.node2graph = nn.Linear(num_nodes*node_emb_dims, graph_emb_dims)#change from ex 1\n",
    "    self.seqGraph2event = nn.Linear(sequence_emb_dims+graph_emb_dims, event_emb_dims)\n",
    "    self.sequence2class_space = nn.Linear(event_emb_dims, num_classes)\n",
    "\n",
    "  def forward(self, adj_mat, node_att):\n",
    "    #node_att: [25, 60], adj_mat: [25, 25]\n",
    "    #prepare for gcnconv\n",
    "    edge_index_tensor = build_edge_index_tensor(adj_mat)\n",
    "    edge_index = edge_index_tensor.to(self.device)\n",
    "    node_attributes_tensor = torch.from_numpy(node_att)\n",
    "    x = node_attributes_tensor.to(self.device)#[25,60]\n",
    "    #lstm on x.T\n",
    "    event_mvts = torch.t(x)#[60,25]\n",
    "    event_vectors, _ = self.mt2vector(event_mvts.view(len(event_mvts), 1, -1))\n",
    "    last_event_vector = event_vectors[len(event_vectors)-1]\n",
    "    #GCN on graph\n",
    "    x = self.conv1(x, edge_index)\n",
    "    x = F.relu(x)\n",
    "    x = F.dropout(x, training=self.training)\n",
    "    x = self.conv2(x, edge_index)\n",
    "    x = F.relu(x)\n",
    "    x = self.conv2(x, edge_index)\n",
    "    #graph embedding\n",
    "    x = torch.mean(x, dim=0).view(1,-1)\n",
    "    graph_vector = x\n",
    "    seq_graph_vector = torch.cat((last_event_vector, graph_vector), dim=1)#[128+16]\n",
    "    event_vector = self.seqGraph2event(seq_graph_vector)#[1,128]\n",
    "    event_vector = F.relu(event_vector)\n",
    "    class_vector = self.sequence2class_space(event_vector)#[1,4]\n",
    "    class_scores = F.log_softmax(class_vector, dim=1)\n",
    "    return class_scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a39b6b4f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a39b6b4f",
    "outputId": "6b5edca8-b076-493d-d575-7ceaadd31e33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n loss: 0 tensor(0.2608, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<NllLossBackward0>)\n",
      "epoch n loss: 5 tensor(0.3288, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<NllLossBackward0>)\n",
      "epoch n loss: 10 tensor(0.1655, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<NllLossBackward0>)\n",
      "epoch n loss: 15 tensor(0.3235, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<NllLossBackward0>)\n",
      "epoch n loss: 20 tensor(0.3032, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<NllLossBackward0>)\n",
      "epoch n loss: 25 tensor(0.2457, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<NllLossBackward0>)\n",
      "epoch n loss: 30 tensor(0.1533, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<NllLossBackward0>)\n",
      "epoch n loss: 35 tensor(0.0999, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<NllLossBackward0>)\n",
      "epoch n loss: 40 tensor(0.0752, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<NllLossBackward0>)\n",
      "epoch n loss: 45 tensor(0.0135, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<NllLossBackward0>)\n",
      "epoch n loss: 50 tensor(0.0426, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<NllLossBackward0>)\n",
      "epoch n loss: 55 tensor(0.0767, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<NllLossBackward0>)\n",
      "epoch n loss: 60 tensor(0.0909, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<NllLossBackward0>)\n",
      "epoch n loss: 65 tensor(0.0018, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<NllLossBackward0>)\n",
      "epoch n loss: 70 tensor(0.0162, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<NllLossBackward0>)\n",
      "epoch n loss: 75 tensor(0.0093, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<NllLossBackward0>)\n",
      "epoch n loss: 80 tensor(0.0005, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<NllLossBackward0>)\n",
      "epoch n loss: 85 tensor(0.1396, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<NllLossBackward0>)\n",
      "epoch n loss: 90 tensor(0.0032, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<NllLossBackward0>)\n",
      "epoch n loss: 95 tensor(0.0188, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "torch.manual_seed(0)\n",
    "\n",
    "NUM_NODES = 6\n",
    "INPUT_DIMS = 896\n",
    "GCN_HIDDEN_DIMS = 2 #kIPF used 4 hidden dims for karate (34, 154)\n",
    "NODE_EMB_DIMS = 2 # number of classes/can be tuned\n",
    "GRAPH_EMB_DIMS = NODE_EMB_DIMS #change from ex 1\n",
    "EVENT_EMB_DIMS = 128 #number of sparsity threshold/can be increased #change from ex 1 #change from ex 10\n",
    "SEQUENCE_EMB_DIMS = 128 #number of timestamps #change from ex 1 #change from ex 10\n",
    "NUM_CLASSES = 2\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "model = MVTS_GCN_RNN(NUM_NODES, INPUT_DIMS, device, SEQUENCE_EMB_DIMS, GCN_HIDDEN_DIMS, NODE_EMB_DIMS, GRAPH_EMB_DIMS, EVENT_EMB_DIMS, NUM_CLASSES).to(device).double()\n",
    "\n",
    "loss_function = nn.NLLLoss()\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.01) #change from ex 10\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-3)\n",
    "num_epochs = 100 #change from ex 10\n",
    "\n",
    "#Train\n",
    "for epoch in range(num_epochs):\n",
    "  #print('Epoch: ', epoch)\n",
    "  for i in range(num_train):#num_train\n",
    "    optimizer.zero_grad()\n",
    "    #print('Event: ', i)\n",
    "    adj_mat = train_adjs[i,:,:]#(25,25)\n",
    "    node_att = train_nats[i,:,:] #(25,60)\n",
    "    class_scores = model(adj_mat, node_att) \n",
    "    target = [y_train[i]]\n",
    "    target = torch.from_numpy(np.array(target))\n",
    "    target = target.to(device)\n",
    "    loss = loss_function(class_scores, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "  if(epoch%5==0):\n",
    "    print (\"epoch n loss:\", epoch, loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c24d6564",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c24d6564",
    "outputId": "a1a34c3e-b632-4f65-da4c-01e7d31b1e45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8020477815699659\n"
     ]
    }
   ],
   "source": [
    "#test accraucy\n",
    "num_test = X_test.shape[0]\n",
    "with torch.no_grad():\n",
    "  numCorrect = 0\n",
    "  for i in range(num_test):\n",
    "    adj_mat = test_adjs[i,:,:]\n",
    "    node_att = test_nats[i,:,:]\n",
    "    test_class_scores = model(adj_mat, node_att)\n",
    "    #test_mvts = X_test[i,:,:]\n",
    "    test_label = y_test[i] #class = 2\n",
    "    #test_class_scores = model(test_mvts) #test mvts = [0.35, 0.15, 0.45, 0.05]\n",
    "    class_prediction = torch.argmax(test_class_scores, dim=-1) #2\n",
    "    if(class_prediction == test_label): #(2,3 ) match \n",
    "      numCorrect = numCorrect + 1\n",
    "  acc = numCorrect/num_test\n",
    "  print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c1ae9fa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7c1ae9fa",
    "outputId": "70add476-0faf-4daf-d253-96ad998dd9f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251\n",
      "0.9365671641791045\n"
     ]
    }
   ],
   "source": [
    "#train acc\n",
    "num_train = X_train.shape[0]\n",
    "with torch.no_grad():\n",
    "  numCorrect = 0\n",
    "  for i in range(num_train):\n",
    "    adj_mat = train_adjs[i,:,:]\n",
    "    node_att = train_nats[i,:,:]\n",
    "    train_class_scores = model(adj_mat, node_att)\n",
    "    #test_mvts = X_test[i,:,:]\n",
    "    train_label = y_train[i] #class = 2\n",
    "    #test_class_scores = model(test_mvts) #test mvts = [0.35, 0.15, 0.45, 0.05]\n",
    "    class_prediction = torch.argmax(train_class_scores, dim=-1) #2\n",
    "    if(class_prediction == train_label): #(2,3 ) match \n",
    "      numCorrect = numCorrect + 1\n",
    "  print(numCorrect)\n",
    "  acc = numCorrect/num_train\n",
    "  print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5249e7",
   "metadata": {
    "id": "3b5249e7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39062690",
   "metadata": {
    "id": "39062690"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95e655d",
   "metadata": {
    "id": "c95e655d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2dcab8",
   "metadata": {
    "id": "dc2dcab8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b3d83f",
   "metadata": {
    "id": "54b3d83f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f74655",
   "metadata": {
    "id": "35f74655"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa507ee",
   "metadata": {
    "id": "eaa507ee"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4e10aa",
   "metadata": {
    "id": "ec4e10aa"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
